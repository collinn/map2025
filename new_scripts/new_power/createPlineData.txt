createPlineData Description

technical description:
* Create a matrix of noisy data for the first group. The pre-period slope is
  centered at zero, and the post-period slope is centered at 0.05 (by default)
* If many means is false, then change the noisy data and set all pre-period
  slopes to zero and all post-period slopes to 0.05 (again, these are the 
  default values)
* Make sure all the post-period slopes are positive
* For each row in the matrix, label the appropriate ID and group and add
  errors (either autocorrelated or normal)
* Create a second group, this time with both pre and post slopes centered
  around zero. 
* Create a matrix of noisy data centered around zero (for both columns)
    Note: it might make more sense to just have one column, since we might not
          want group B to have any changes
* If many means is false, set both slopes to zero
* If the groups are paired, we know the IDs should match and the intercept
  should be the same among the two lines (optional)
* For each row in this matrix, label the appropriate ID and group and add 
  errors (either autocorrelated or normal)
  
description for paper (!!!WORK IN PROGRESS!!!):

To demonstrate the relationship between effect size and power, we
simulated data from two groups whose mean structure is a piecewise
linear function defined as follows:


y = {b, t < 0
     mx + b, t >= 0.
     
Group A: m ~ N(0.25, 0.05 or 0.025)
Group B: m ~ N(0, 0.05 or 0.025)
for both: b ~ N(0, 0.05 or 0.025)

Settings either generate single means or many means. (** talk about what many
means means in terms of the normal distribution**).
Additionally, we generate data with and without autocorrelation. 

TAKE TWO (** WORK IN PROGRESS **):

The power simulation will describe the relationship between effect size and 
power by simulating piecewise data from two groups, whose mean structures are 
defined as follows: 

group A: y = {b, x < 0
	      mx + b, x >= 0
group B: y = b

For both groups,
b ~ N(0, 0.025 or 0.05)
m ~ N(0.025, 0.025 or 0.05

Several settings are shown in the simulation. The first distinguishes between 
the "many means" structure and the "single means" structure. In the single 
means structure, during each iteration of generating new data, the parameters 
of the function stay constant and the only source of variance is the error 
term. Meanwhile, the many means structure resamples function parameters from 
a normal distribution for each iteration of data generation. This ensures 
that within-group variability is accounted for in the simulation. 

The second setting, autocorrelation, is set to true or false to distinguish 
between IID and autocorrelated error terms. The third setting, bcor, takes 
autocorrelation into account when fitting the data using the bdots package. 

The results of this simulation tell us two things. If the method finds a 
difference before x = 0, the method has committed a Type 1 error, since 
the two b parameters were drawn from the same distribution, so there should 
not be a statistical difference between the two groups. Alternatively, if 
the method fails to find a difference after x = 0, the method has committed 
a Type 2 error, since there should be a statistical difference between the 
two groups. Thus, the simulation shows that although the two new 
methods -- heterogeneous bootstrap and permutation -- are more conservative 
in their estimations of confidence intervals, they still demonstrate power 
to find true statistical differences.
